{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PfZ3Hm8dQaZa"
      },
      "outputs": [],
      "source": [
        "! pip install langchain-core langgraph >0.2.27"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fZHgG7idQkQQ",
        "outputId": "42b4c698-b80f-4cf0-872f-410487dd05e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.62 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.63)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.11.4)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.3.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (4.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.5-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain-google-genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-google-genai-2.1.5\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "a83221213a3b4157bfa58f2cd75596c6",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "! pip install -U langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kwCRpFa0Q2kg"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "model = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsgqxJ5-Q4vg",
        "outputId": "938741b7-0339-4fa6-d056-993cd26692ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--d4470038-7c02-4d6a-8947-a43a81562889-0', usage_metadata={'input_tokens': 1, 'output_tokens': 11, 'total_tokens': 12, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "model.invoke([HumanMessage(content=\"Hello\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3Q6K7iMRA96",
        "outputId": "effc1bf7-c051-4e53-c3f5-d1d4252426d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/2.5 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fbNkpzaRbpD",
        "outputId": "20b0d3b0-b01e-4358-9a58-0e0785b58264"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install -qU langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "x9reA1pPRxO5"
      },
      "outputs": [],
      "source": [
        "#open ai embedding model\n",
        "# import getpass\n",
        "# import os\n",
        "\n",
        "# if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "#   os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
        "\n",
        "# from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mXcV1pmwSzW-"
      },
      "outputs": [],
      "source": [
        "#Gemini embedding model\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
        "\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iMDqog7lSIn0"
      },
      "outputs": [],
      "source": [
        "! pip install -qU langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8yvUnigSVtt",
        "outputId": "0b5e6227-df15-4985-995a-0cc3aa384905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install -qU faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDlvQ-zySNhS",
        "outputId": "1c8b1060-ad40-447c-ddac-e568b6fafaa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "768\n"
          ]
        }
      ],
      "source": [
        "#using fiass vecto store to store embeddings\n",
        "import faiss\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "embedding_dim = len(embeddings.embed_query(\"hello world\"))\n",
        "print(embedding_dim)\n",
        "index = faiss.IndexFlatL2(embedding_dim)\n",
        "\n",
        "vector_store = FAISS(\n",
        "    embedding_function=embeddings,\n",
        "    index=index,\n",
        "    docstore=InMemoryDocstore(),\n",
        "    index_to_docstore_id={},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZuSKC6uT9aw"
      },
      "source": [
        "In this guide we’ll build an app that answers questions about the website's content. The specific website we will use is the LLM Powered Autonomous Agents blog post by Lilian Weng, which allows us to ask questions about the contents of the post.\n",
        "\n",
        "We can create a simple indexing pipeline and RAG chain to do this in ~50 lines of code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snnutwn2SOF0",
        "outputId": "9fcab8d9-52f2-4d1e-8e25-ac9d8da7080d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import List, TypedDict\n",
        "\n",
        "# Load and chunk contents of the blog\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "# Index chunks\n",
        "_ = vector_store.add_documents(documents=all_splits)\n",
        "\n",
        "# Define prompt for question-answering\n",
        "# N.B. for non-US LangSmith endpoints, you may need to specify\n",
        "# api_url=\"https://api.smith.langchain.com\" in hub.pull.\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "\n",
        "# Define state for application\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    answer: str\n",
        "\n",
        "\n",
        "# Define application steps\n",
        "def retrieve(state: State):\n",
        "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
        "    return {\"context\": retrieved_docs}\n",
        "\n",
        "\n",
        "def generate(state: State):\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
        "    response = model.invoke(messages)\n",
        "    return {\"answer\": response.content}\n",
        "\n",
        "\n",
        "# Compile application and test\n",
        "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xsqj8ZRtUGfA",
        "outputId": "d4eb0b58-ab3c-43ba-8965-c3d51d063124"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task decomposition is a technique used to enhance model performance on complex tasks by breaking them down into smaller, simpler steps. This can be achieved through methods like chain of thought prompting, task-specific instructions, or human input. Another approach involves using an external classical planner to do long-horizon planning.\n"
          ]
        }
      ],
      "source": [
        "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVVsYlZlXryC"
      },
      "source": [
        "# Query analysis\n",
        "So far, we are executing the retrieval using the raw input query. However, there are some advantages to allowing a model to generate the query for retrieval purposes. For example:\n",
        "\n",
        "In addition to semantic search, we can build in structured filters (e.g., \"Find documents since the year 2020.\");\n",
        "The model can rewrite user queries, which may be multifaceted or include irrelevant language, into more effective search queries.\n",
        "Query analysis employs models to transform or construct optimized search queries from raw user input. We can easily incorporate a query analysis step into our application. For illustrative purposes, let's add some metadata to the documents in our vector store. We will add some (contrived) sections to the document which we can filter on later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSxQE3wtUV3U",
        "outputId": "a4d5d0e7-a5e8-44eb-b071-3c0215f278a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from typing import Literal\n",
        "\n",
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import Annotated, List, TypedDict\n",
        "\n",
        "# Load and chunk contents of the blog\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "\n",
        "# Update metadata (illustration purposes)\n",
        "total_documents = len(all_splits)\n",
        "third = total_documents // 3\n",
        "\n",
        "for i, document in enumerate(all_splits):\n",
        "    if i < third:\n",
        "        document.metadata[\"section\"] = \"beginning\"\n",
        "    elif i < 2 * third:\n",
        "        document.metadata[\"section\"] = \"middle\"\n",
        "    else:\n",
        "        document.metadata[\"section\"] = \"end\"\n",
        "\n",
        "\n",
        "# Index chunks\n",
        "vector_store = InMemoryVectorStore(embeddings)\n",
        "_ = vector_store.add_documents(all_splits)\n",
        "\n",
        "\n",
        "# Define schema for search\n",
        "class Search(TypedDict):\n",
        "    \"\"\"Search query.\"\"\"\n",
        "\n",
        "    query: Annotated[str, ..., \"Search query to run.\"]\n",
        "    section: Annotated[\n",
        "        Literal[\"beginning\", \"middle\", \"end\"],\n",
        "        ...,\n",
        "        \"Section to query.\",\n",
        "    ]\n",
        "\n",
        "# Define prompt for question-answering\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "\n",
        "# Define state for application\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    query: Search\n",
        "    context: List[Document]\n",
        "    answer: str\n",
        "\n",
        "\n",
        "def analyze_query(state: State):\n",
        "    structured_llm = model.with_structured_output(Search)\n",
        "    query = structured_llm.invoke(state[\"question\"])\n",
        "    return {\"query\": query}\n",
        "\n",
        "\n",
        "def retrieve(state: State):\n",
        "    query = state[\"query\"]\n",
        "    retrieved_docs = vector_store.similarity_search(\n",
        "        query[\"query\"],\n",
        "        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
        "    )\n",
        "    return {\"context\": retrieved_docs}\n",
        "\n",
        "\n",
        "def generate(state: State):\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
        "    response = model.invoke(messages)\n",
        "    return {\"answer\": response.content}\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
        "graph_builder.add_edge(START, \"analyze_query\")\n",
        "graph = graph_builder.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "xxQEI9wuY63G"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "k3JyxvKGX5Jl",
        "outputId": "aacbe7d1-bcd0-48b5-b85e-9290c83a1e77"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJYAAAGwCAIAAADE4QsqAAAQAElEQVR4nOydB1gUR9/A53o/eheQakGxgGJFsESjYI9iR8XYkxiJms8ao2+iGGOKLTHGJNao2EsSMSp2jQ1rRJpIPeo1uMb3x8t7L9EDU9jjZpnfw8Ozu7O7t7u/nf/MbJllV1VVIQLOsBEBc4hC7CEKsYcoxB6iEHuIQuxpeIWlhVp5sVZZrlfJ9dpKA8IBDo8hlLBFUpbUgWPjyEENCqOh2oV56RVPUhTp95T2rlwwJ5KyxbYcFiZBQaetUpbplOU6NpdZWqDxCRL7tha7NuWhhqABFBY+q7x4tEhiy7Zz5jYNEtk5N/BZ/C8pydfAiVhaoFWU67pEOTq6c5FlsbTC84dl2Y/VXaIcvJoJEb3IfKi6eETm1UzUdaADsiCWU2gwoF2rM7tEOfm0opu8mqTdVV4+XjT6PS/EQJaBiSyCQY82zkvtP8md3v4A31aifuNdv5ybarBUzcwSuVCvrfpqYdr01X6oMbE+PnX6an8m9XnEErlw15qsURBYGhmj4r12JWQh6qE8FyYflHk2EzZtQfP4aRaoqT5LVXcb5IiohNpcmJtRkZ9V0Tj9AT5Bopx0dX5WJaISahVePCqDphJqxMDuw0FAVEKhwqePVE7uPHdfPmrENPEXwBUMaAojyqBQ4eNbCkcPS19z6t2797Nnz9DfZM+ePUuXLkXUANdrHt+SI8qgUCE0cqEwQBYkOzu7tLQU/X3u3buHKMOnlTj9rhJRBlU10rzMytvnSvqOc0UUANu8c+fOY8eOZWVl+fj4hIWFTZ8+/dq1a7NmzTLO0KNHj08++eTJkyf79u27evVqXl4ezDZs2LAhQ4ZA6qNHj8aMGbNu3boVK1bY2dkJhcLbt28bF9y+fXvz5s1RfXPyu7z2Pe2cPSmJSVTdGoDr9ywWVZeYdu/evXHjxgULFnTu3PncuXPr16+XSqXjx48HK++8886hQ4c8PDxgtoSEhIKCgoULF/r6+iYlJa1cudLNza1Tp05cbvWVaFhq3Lhxbdu2DQoKio2N9fb2/uCDDxA1MFmM0kINZgpVch3cUUPUcOPGjZCQkKioKBiGjBUaGlpRUfHybKtWrVKpVKANhocPH37gwIGLFy+CQhaLhZ7nVMiLyCIIJSxVuR5RA3UK9WJbqlbepk2bL774Yvny5eHh4eDS09PT7GwGg2HHjh2gDeKtcQqEU1NqixYtkKUQSllKuQ5RA1VHmcFksDlU1ZVGjRoFBRiE0Pj4eDab3bdv39mzZzs6/qkBqtfrYSKUmvAfsqlEIoFoWXMGHs9ytWU2m8lkUHXZmyqFfAFTXqJF1ACRcOhz0tLSrly5snnzZqVSuWbNmprz3L9//+HDh1BkdujQwThFLqewZl838lKtQMxC1EBVRoHQAbEUUQBkrKNHj4I8GIZ6CuTImJgYsPXCbMbWhZOTk3E0NTU1MzMTNRBQEFJXM6BKodSey6TmtGMwGKBw3rx5ycnJ5eXl58+fP3PmTHBwMCQ1bdoU/p86deru3bt+fn4wJ5SFCoUiPT197dq1UJHJzc01u04oTSHXXr9+vbi4GFEAi82Q2uGm0MOf/+i6XKehpNG5bNkysDVnzpyePXtC2y4yMhJaDjC9SZMm0dHREDyhsuPu7g5Jt27dioiImDt37syZM6FSCu2/kSNHvrxCiMmQuWfMmPH48WNU32gqDHChyt1PgKiBwptNP/2Q59tKHNBOjBo3j36TZz1U9RnjgqiBwgtsAW0kBU8rUKOnMLvSL5jC85jCBzd9g0WXjstahkntXMw/l5eRkfFCRd8E1DmhVWA2CeKh6UJavQOtFCgRzSbZ29vXVlIuWrQILq+bTSrK1Tz9XUXpXV9q79rDbet7l8ujJruZTdVqtYWFhWaToAEALTmzSSKRyMbGBlGDTCbTaDRmk+ACEJ9v/sYZXGgVCMwXdUe+ygnubutN5U1vah+fhjsVT+4o4ba1i5eZdjSHw4FKB7ImXrg+8C/Jy6gQStneFD+0QPnjT71HOSd+ma3XNrrXwbWVVYc2PesV44woxhJPsI16z2vHaks8y2VV7FydOWqeN6IeCz3NrVYY9n3+dMwCb6YlzpkGRq+r2vFx5og5XnyRJfbWQkdUIGZGxblvnJdalKNBtKYwW7P5/bSBUz0s4w9Z/rWYn3fkG3RVXaIcpA54v9D0MmUy7YUjMg6XSV0r3iwN8HJa6i3FxaOywBCJcxM+VFkZmIdWg7667QTt98e35F2iHP2CLfq4EGrAV0R/vyEHl7DzQZ2rG3kiKUtsy2FjkjOhtqks1ynL9XDwHlwpaxokCmgraahLiQ2m0MTTR6pSmVb1/EVtTUU935+C+/Vwv6K22/r/GA6fKZKw4YaarRPXM5Cq69d/kYZXSCmbNm2C2/pxcXGIvpAeL7CHKMQeohB7iELsIQqxhyjEHqIQe4hC7CEKsYcoxB6iEHuIQuwhCrGHKMQeohB7iELsIQqxhyjEHqIQe4hC7CEKsYcoxB6iEHtorpDL5XI4dHt54wVorlCj0RgMeHzK6x9DAin2EIXYQxRiD1GIPUQh9hCF2EMUYg9RiD1EIfYQhdhDFGIPUYg9RCH2EIXYQxRiDz27Dho4cCCDwYA7hXK5nMlkisVi2E0YPXbsGKId9MyFnp6eFy9eNH4hDSgvLwd/Xbt2RXSEnj28Tpo0yc7OruYUW1vbCRMmIDpCT4UhISEvfAy0VatWoaGhiI7Qtp/liRMnSqVS47CDg8PkyZMRTaGtwg4dOrRu3do43LJlyzZt2iCaQufezmNjYx2eU9s3aejBq2ukKrmhKKdCUU7Vd0ypg4/82gdGQ12Uq/F5cK0c4YZIwnZ05wulr8hmr2gXntpV8OyJ2saBwxeTiwCWRi3XyUu1Hn6CXiPr+l5JXQoPbc71aibybydFhIbj99/Kc54oo6e41TZDrQpPbMtz9xP7Bjf2rw9aA6m35PmZqn7jzX87wXyczc+q1GqriD8rwb+tpFJtKMyuNJtqXqEsp5InoOoL0IR/AE/ABClmk8xXUlRlOqk9zV8IwgupA1dRZv4LEOZzocFQ/e0oRLAaQEeVwbwR0lTAHqIQe4hC7CEKsYcoxB6iEHuIQuwhCrGHKMQeohB7iELssdJnZ9LSUiN7haak3EKEV0FyIfYQhdhTbwrT058cPrLvtxtXCwryvL18oqOHRQ0YYkwaOChy9OiJSqVi+46tIpGoY4cus2bG29s7QNKlS8mnf/3p9p0bCoW8RfNW48bGtW0bUnO1X2/58siR/Yn7f2Gz/9jU/ft3bfrqs23f7hs7bvAL2/Be/OL+rw+CgeMnDh05mpiR8cTXNyAyos+woaMYDEbd269SqVZ+tOjGjas6nS5u8syiItnVaxe3bd0LSa/16zxp4vSYkeONc360aunTp5kbvtwGwzJZ4YaNa+/dv6NWq8PCuo4fG+fp6Q3TH6c+enPqmI9WrluzdoWtrR2fLxCLJR//5zPTzy1eEq9Wq9YkbED/mnorC7/4MuH6b1fefef/du882r//4E/Wrrx2/bIxicvj7dz5LY/HP3zo121b991Jufn9D1+j50dtxX8WwiH7YFnCt9/s9fDwXLh4TmlpSc3VRkUNlSvkFy+dM005m5zUrWuEi7Pr2k82mf76vhYFjps3C4IZfvnleMKaD5s3a7lz++GJsdP27tuxfsPaV27/2nX/yUh/8tm6LXt2HSssLDhx4hCXw617Edjyd+Onpdy9FT93MciWSm1mzorNyX1WvcvPl92ydf3IEePmvrsITqxr1y6VlZcZF6yoqLh85Xxk5GuoPqg3hUuXrkpYtR7yEJx0gwYOD/BvdvXqRWMS5IBmzVqOHTNJIpY4OjqFhIQ9eHAXpguFwi1f737n7QUtmge5uLi+OeUtkHr37u2aq3VzdQ9p3/H06Z+Mo5A5oI7zWp8BIKxd21Djn0Qshaw8L36Jr68/zHPkWGJwcLu335pvZ2cfGhI2KXb6wUM/lpWV1rHxCoXi7NlTI0aMCwxoDuFh5ox3bWztXvnaHgQPyI7vL1jeIbQTLDVrxlyJ1CYxcTckGV+q6tqlxxvDx8De9e71OpfLTUo6aVzw/IUz8D88vBeqD+otkFYZDHv37wBt2dlZxine3j6m1MDAFqZhCCkQVI3DKqVyy5Yv4ViAG+OU0rKSF9YMefqjj5eAXVB+5uwpGxvbjh27mFJh+qIl78Jp3qdPf/Q8Z9y/nxI7YapphnbtOuj1ehDfrVsEqoWsrHRYsEWLVsZROOcgE2dkpqE6gXVyOJz27TqYlmrbJiQl5eb/9jrgj70GfxAnTiWdGDpkJIwmJ58Gu3BCo/qgfhTCMZq/YDactm9Omd22OltIZsyKrTmD2aIoLy/37TlxHUI7L174n5YtWxsMhn79zbwCGN695+dfrP71zM8D+g8+l5wEWdD04iAAodje3nH2rPeMoxCjYGO+2boB/mqupKS0GNVOcXER/BcKhKYpUHqhVwHlt1arhcZPzYkODo6mYShBTMPRUcPi3hyVn58Hp+CVqxdgl1E9UT8KHz26//vjh5+s2Wg6JWH3XrkURD84BPPnLePz+eh5kDQ7G8RMOIV//uUYnLl37tx8e/Z8U9Ku3d9BTP7m690mqWKxGNbWr2/0C2HKw92zji2Bw4qe6zdNUamUtc1s0P/xGBLYEggEK1d8+qetZZk/pH5+AZCzj5846OPjLxAIoe6D6on6UWgsaRwdnIyj0DCHQqJZjeBZ21ISidToDzh7Lqm2OaOjhv64dzv8QVllLPAAKDW/+/6rTxI2Giu3JqAWqq5QQxlpHNVoNPn5uc7OLrVvCHJ1dYf/9x+k+PsHImM0fpAi/m+g4/F4UHs0zZyVlcF6Xj2u/iG1GpZ1e7448Cwn297OobZfgRJh3/6dcHCgaDRVsP899VOdaerjB6ES6n5QL8jMTId6NpTwefm5dS/l7xcIOe/Y8YNwyC5fuQClCFTqoE3y8pxNmnhBMZN4YDdkR+OUkpLiJcvei4joo9Fqbt66bvyDowNJU6e8de5cErQrIDJDrl2+4v25702vrKysY0ucnJxbtWoDsRccQDth3Wcfm0prICioTfL5X5XK6nz5w/Zvior/iBZhHbtAqZyQsBzCI5yOiQf2TJ8x/sTJw7X9Sq+e/WDvrl2/ZGz51Bf1oxBOw4X/twKq19GDIhYtmTt58syBA4dDLpkUN7KOpXr3fn3M6InfbtvUp2+nAwf3QHkG5Rwco88+X/XyzF26hEMh16tXP+PopcvJYPGnn46+O3ea6Q8yJSRBdXTzxu0gb8iwPu/Nnwk1phUfruXVKJbMAhVLCBtxU2LeGPk6RNHu3XqakmDDbG3sogb2gO2srKyAPKTX/fGeF7T8IGLDWTJ4aG+o90IAN1ZYzALVMaiNQ6PZx8cP1R/m36m4cqJYq0Vtetgjq2He/Fm2dvb/t2A5sgjQrn3w8O6Wr3ah+gPK2hEjX5869W2ol6G/ya0ziAqxiAAAEABJREFUxTw+6tjXjBFrv8AGhY1Wp923bwdUl6DagvAE9qKoqHDDpk+hxKnfKIqsX+Hjxw/fnjMFGv7LlqyqWV//u9y7d2fB+2/Vlrpr51GoyiLKgFoClBdBQcFLF3/8ykt9fxdsAum/Jzcvp7YkU5XSasE4kNYj1u/pn0FuNmEPUYg9RCH2EIXYQxRiD1GIPUQh9hCF2EMUYo/5m018EZPFrudLeYR/A+jgi8z3BGReoZ0zNy9DjQhWQ266yt7F/EOR5hU2CRRqKvR6Lel6xirQaarAhYef+SeyzCtkMlH4EKekXbVe2idYktO7ciKGOTFqecKirs4sC7Mr93+RHdzD3s6ZV1sgJlBHhUJXWqi9+WvRiDmeju61Plr+ii5lIQvfPFNSkFWpKMOvV2BAoVRCrUwkEiEMEdmwXLz47Xva1V21pOfXYkxs2rSJzWbHxcUh+kLahdhDFGIPUYg9RCH2EIXYQxRiD1GIPUQh9hCF2EMUYg9RiD1EIfYQhdhDFGIPUYg9RCH2EIXYQxRiD1GIPUQh9hCF2EMUYg9RiD00VygUCuux20jrhOa7p1KpiEKCtUMUYg9RiD1EIfYQhdhDFGIPUYg9RCH2EIXYQxRiD1GIPUQh9hCF2EMUYg9RiD307DpowIABxv0yfrFOLBbDKIPBOHbsGKId9MyFHh4e169fZzL/6HgORBoMhtDQUERH6u2L2lbFuHHj7Ozsak6B0bFjxyI6Qk+F3bt3DwgIqDnF398/PDwc0RF6KgRiYmJsbGyMwzAA+RLRFNoqjIiICAwMNA5DFuzWrRuiKbRViP6bEaVSKY2zILJ8jbRCZSgp0CKLtGQCvcJa+naFtoSfR2huegWiHgajumd6ntCiGcNy7cKcJ+rrSaV5mWqvZmJ5sQbREak9N/Ohws1HENrbzs2HjyyChRQ+S61IPlTYc6S7QEL/Pr5Vcv3p3Tk9hjm7+/AQ9VhCIQSxs/tlA6Y0QY2JI5uf9opxdvGi3KIlovZvp0vCh7mgRkaPYa6/nSpB1EO5QoMeZT5QSuw5qJEhdeSk3VUg6ospyhWWFmo9m2H5jYF/j1dzUUkB5RU3CzQqquTFWtQoKS+yRMWb3C/EHqIQe4hC7CEKsYcoxB6iEHuIQuwhCrGHKMQeohB7iELsofOzM4uWzJ03fxaiO9grHDy0d07uM7NJET369OrZD9EdvAPps5zssrLS2lJ796K/P2SdChcviedyuc7Orrv3fP/BstXh3XvKZIUbNq69d/+OWq0OC+s6fmycp6f3teuXjXFyzNhBXbv2WLH8k+iBERNjp51NTrpz5+ahg6dXJ3ygqaxcvepLmMfsGpRK5eChvSZNnD4qZoLxp/V6/cDBkUOHxEyeNMPsIsj6sMZAyuFwHj26n5aeuvLDtcGt2+l0unfjp6XcvRU/d/G2rXulUpuZs2IheHYI7fTRynUw/47th8Bf9YJcbuKB3f7+zRJWrxcKhKYV1rYGkUgEbpLP/2qa8/pvV1QqVd++0bUtgqwPa1TIYrFkRYXLlyV06RJua2t3+86Np08z31+wHJzZ2zvMmjFXIrVJTNxtdkFHJ+fZM+NDQ8Jq9mFZxxp6hPd+8OBuUZHMOOf587/6+wU28fD86z/a4Fhpdcbby4fH++PZr5SUW5Av27frYBxlMBht24SkpNw0u2BgQIuXJ9axhu7dIuGHzp49BcNVVVVnzyX17Nn37/5ow2Kl1Rku73/P7ikUcq1WG9nrT28HOjg4ml+Qy315Yh1r4PP5nTt1P3f+9NChMaBNLi/vGdn37/5ow4JBjRQOnEAgWLni05oT2ay/seV1ryEios8HyxdAzfZc8ung4HYuLq6oPn7UYmCg0Nc3AOqErq7ubq7uxinQlrC3c6ivNUAuBFsXL507lXQCaqf19aMWA4OmfVjHLh07dklIWJ6fnwd5JfHAnukzxp84eRiSPL2awn8oye4/uPvP1oCex94uXXocPPgjBM8e4b3+yiJWBR5Ne2g8HD6yf/mK9+/fT4HGWb++0UOHjITpHu5NYHjrtxtbBbX5dO3mf7AGI5E9+ixc/G6nTt1sbGz/4iLWA+XvVBTnaU58lzdwmhdqfBzakDlgkpudCxdRCblTgT1EIfYQhdhDFGIPUYg9RCH2EIXYQxRiD1GIPUQh9hCF2EMUYg9RiD2UK2QwGbZO1F6qt1psnblMFuV3ZCn/ATtnTtZDpV5Lw07c60ZbaXj2WGXjSHkmscRd+2ah0oKnluhL0qoozK4IDJEi6rGEwsjhTkm7c+CsRI0GTYXh9K7cyDecEPVYqDNL8Ld1aXrYAGeJLcfWmVdloGdcZTAYpYWV8hLt1ZOFE5f6cHgMRD0W/dTIlRPFTx+rWCxmUa6F4qpeb4CjaIE6hREHd55eV+UZKAzrZ48sBT2/FmNi06ZNbDY7Li4O0RfSLsQeohB7iELsIQqxhyjEHqIQe4hC7CEKsYcoxB6iEHuIQuwhCrGHKMQeohB7iELsIQqxhyjEHqIQe4hC7CEKsYcoxB6iEHuIQuyhuUKJRMJisRCtoblCuVxes5NuWkICKfYQhdhDFGIPUYg9RCH2EIXYQxRiD1GIPUQh9hCF2EMUYg9RiD1EIfYQhdhDFGIPPbsOGjFiBIfD0ev1JSUlDAbD3t7eYDDodLp9+/Yh2kHPXAh36h88eMBk/tFvl0wmA52BgYGIjmDwCcp/wJgxY/h8fs0pAoFgwoQJiI7QU2FUVJS3t3fNKV5eXv3790d0hJ4KgdGjR5u+ri0SicaOHYtoCm0VRkdHQ84zDvv4+EC+RDSFtgrR8xIRMiKUgjExMYi+WKJRoZLrUQMxZcoUNpu9ceNG1BAwEEMgoTyTUKhQW1l1/pDsyR25s5egMLvRda8OOHnyC7Iq/FqLuw92ZHOp6uSZKoWQ875fkdF7tLutM5cnpPnz1HVQodSXFmhO7cyJXeIjEFOSIylRqNNUfb04bez/+SHCf/nhw9Rpq/yYrPrPi5QoPLOv0N1P7OYrQIT/8ixVlZ+h6jHMEdU3lGTttLsKG0cOItTAxpGbfk+BKKD+FWrUBnsXnlBK7oH8CbEtGyxS8b0VCg40AzXCz/v8FQqy1NVHp74heQV7iELsIQqxhyjEHqIQe4hC7CEKsYcoxB6iEHuIQuwhCrGHKMQeOj/+9C9JS0uNGY3Bc28kF9bKg4d3EQ5Yi8JDh/ft3bu9XF7euXP3SbHT4fRfsvijyIg+kHT8xKEjRxMzMp74+gbAlGFDRzEY1bdsFi+J53A4HTt22bBhrbpCHRQUPPXNt1s0D4IknU739ZYvL185X1iY37p1uyGDRnTq1M34Q9EDIybGTjubnHTnzs1DB08zGcy9+7ZfvXoxIzPN3t6xW9fqVD6fv+Wb9Tt2fgvzR/YKnTF9zhvDx8hkhRs2rr13/45arQ4L6zp+bJynpzeyAqwikN67d2fdZx/36tXvh+8Su3eN/ODDBej5qy3w/5dfjies+bB5s5Y7tx+Gg7t33471G9Yal+JyudevX750KXnTpu0njp3ncrirVi8zJn267qPEA7tB9q6dR8O791z6wbxzyaeNSRwuF5L8/ZslrF4vFAj37d+5c9e2mJgJsP7ZM+OTTp/cvuMbmC1u8syYkeNdXFx/TboO/uCceDd+WsrdW/FzF2/bulcqtZk5KzYn9xmyAqxC4U8/H3VwcJww/k0bG9tu3SJC2nc0JR05lhgc3O7tt+bb2dmHhoRBBj146MeyslJIMr64NH/eMnc3DzabHRHRJzMzXaVSVVRU/PzLsdGjYgdGD7OR2gzoP7hnZN/t278xrhDODEcnZ7AFa4OlwNOWr3b1CO8F64ecGtGjz7Vrl17ewtt3bjx9mvn+guUdQjvZ2zvMmjFXIrVJTNyNrACrUAhBLKhlsOldsu7dexoH4Ny/fz+lQ2hn05zt2nXQ6/UpKbeMo55eTYVCoXFYLJag6g5Iyx8+vAcL/mmptqGPUx8plUrjaGBAC1MShOKr1y5OnzmhT99OEDP3J+4qLil6eQvhF2HO9u06GEchkrdtE5KSchNZAVZRFiqVCjc3D9Oog/0fj3lBfgJh32zdAH815y8pLTYOmKzXRKGUw//Zb09+YXpxsUwkEqHnEdg0ccOmTyFWvzllNiiHsLn5q89PJZ0ws06FXKvVguOaEyFyICvAKhTyeHy9TmcaLSqWGQfEYjHULPr1jQ4P71Vzfg93zzrWZv/8DJj77kIPjz/N5ujo/MKcBoPh+PGDI94YGzVgiHEKqDK7TrAlEAhWrvi05kQ2yyqOnlVshJurO8RS0+iFC2dMw1ALhdomRELjqEajyc/PdXZ2qWNtUFGEfAZlnmmp4uIiCH3g4IU5YW2Q0R0cnEyjly4nG6u7L1C9GWq1q6s7bKpxyrOcbHs7B2QFWEVZ2Llz+JMnj/f8+ENVVdW165dNRR0wdcpb584lQbsCcgw0A5aveH/ue9MrKyvrWJtELImdMHXbd5thPWDlzNlT782f+dnnq16eE7I45NSTPx0BH1BFWr1mOVgvLy8Dr5DapIlXUZHswoWzUJEJ69gFWi8JCcvz8/NgzsQDe6bPGH/i5GFkBViFwp6Rrw0ZPAKaYkOG9TlwcM+UKbNhIodd/TAxVEc3b9wO8iAJTKiUyhUfruXxeHWvcFTMBKj979y9LXpQxOdfrIbA+178ErNzQusT6imxE4ePHTe4Q0inSZNmQONk4ODIgoL8TmHdWrdqu2jJ3KTTP8GcH61cB/EczqHBQ3tDrRjC+9AhI5EVUP8P5GsqDNuWZ4ya7/vXF4EKZEZGmr//H90ZPHh4b8bMCVu37PHxodVbGTs/ejLpA18Or54fJbWKXHjz1vUpU0dDdsnLy4VWxGeffdy6dVua+aMOq6jOQHt5zjvvQwN/UtwIaN6FhnSaNu0dRPhrWMs1UriSAn+I8PchdyqwhyjEHqIQe4hC7CEKsYcoxB6iEHuIQuwhCrGHKMQeChRWIWdPPiK8hIuXgIIOLyi4U8EVMEvyNapyHSLUQFGqKyvScCjoTI+Sm02+rUWlhVpEqEFZoca3lRhRACUKuw92OrXTKh6TtR5O7czpPpiSJ96o6syyQmXYuiSt1xh3W0duY+7MS1mmg/z3y46cKSt9eQJ8OrM0YtCj5EOFaSlKexdufgN16WUwVO8dk0lVd651A9U6qBb4BVd3KcugbBMs0bFzpbr++477i2zdupXNZo8fPx41CFWIJ6T80RZLhDiKAshfgcHSMVgNuQEWgDTtsYcoxB6iEHuIQuwhCrGHKMQeohB7iELsIQqxhyjEHqIQe4hC7CEKsYcoxB6iEHuIQuwhCrGHKMQeohB7iELsIQqxhyjEHporFIvFHA7Nv+1Nc4UKhYLNpvk+kkCKPUQh9hCF2EMUYg9RiD1EIfYQhdhDFGIPUYg9RCH2EIXYQxRiD1GIPUQh9hCF2EMUYo8len+yPCNHjnz8+DHsGoPBYIBpaKwAAAa/SURBVDKZBoMBhn18fBITExHtoGe3SMOHD+fz+SwWy/ixX/gvFApHjRqF6Ag9FQ4ePNjb27vmFC8vr6FDhyI6Qk+FHA5n2LBhpo+NwgCMQqZEdIS2/csNGjSoSZMmxmHIgqAQ0RTaKoSMOGLECCgRjVmQwWiYLkktAD1rpEZ0Ot3o0aNhYNeuXXSNoshKFOZmVKTfVeVlVqgVerVCx+Gx1eUaVB/oDdW92bKY9RNshDZcTYVOIGYLxCxXb75vK6Fr04b/nENDKtRqqq6cKLl3pZQn5IidxDwBm81jsblsFoeJrDM0MJBea9BpdLpKvUallcuU8L9lJ9tOr9uxOQ0WqBtMYfKhopTzpe7NHSWOQhYX1yJZpzHIZarch7Lg7nbdBtqjhqABFMpy9Se/z+WKBc6+toguFDwp1arUr8e62TtbutC1tMKsR6qT3+X7d/ZksulWRYQYm3ope8Bk1yb+AmRBLKowL6vy5x2FXm3dEH3Jupnbb4KzswcXWQrLFUIF2RUntuXT2x/g1c7t6JZcWU4lshQWUgh1+x8/zfbp4IEaAb4dm+xe8xRZCgsF0iNf5TLFNiI7HmocKIorqlTy6CmuiHoskQuzH6tLi/WNxx8gtueXyHTPnqgR9VhC4dlEmaNPw7SZGhDY5XMHZIh6KFeYl15ZhVgCqZVmwXK5LH5x2J17v6L6RmjD0+mZ+ZmUf2+McoWPb8t5kkb6XVi+hP8kRYkohnKFaXeVUmchapRInIRP7lCukNon2JRleq6AzRNR1W1IWXnh4RPrMp+maDTq5oFdeveY5OxU/bxF8qXdp899P2HUxz8eWFkgy3Bz8Q/vOrpDuwHGpW7e+flk0uaKCkXLZt26d4lBlMEXc1lclkquF0oovOpGbS5UyXWVKj2iBr1et+nbmemZt98YtDB+9m6hwOaLryYXFVd/gJbN4qrU5QePrR05dFHC8sutW0bsPbiytKwAknLzU3fuWxLarv/8t/e2b9MP5kFUArsPChGVUKtQWa6H+0eIGtIybhbKMkcNX9YsIEwqcRjUf45QaHP+8o+QxGAy9XrtwP7veHu2hvv1IW37Gwz67JyHkHTxyn5bG9c+EZOFQmmAX4ewkIGISjh8FtUfF6c2kFaqDQIJVXXR9MxbLBYnwDfUOAqq/Hzaw0TTDF4eQcYBAV8C/9UVcvgvK37q6uJrmsfToyWiEr6YV6mi9iOq1CrkcBlqRf3cf38ZdYUCsho0CWpOlEr+99Vqs8/LqFTlzo7/ez6Ry6X2rkKFQsPmUfsT1CoUSlk6DVUlgUTiAAImjfmk5sRXPiMD8VOr+9816MpKamuMsPsiij8oTu3aYesNWqrCiLtLAFRE7e3c7O3cjVNkRdngte6l7GzdHjy6YDAYjA96P/j9AqIS2H2qvwlPbXVGYsfWVT9sQklGbB7YuXlA5z0HVpSU5imUpVCR+XzzxGs3jtS9VJug3nJF0ZGTn8H1/dS03y5dpfAtC12lHs4VsQ219/Epf7OpaUuRvFBl5yFBFDBp7NpL1xK3/7gImoZOjt6h7aK6dRpR9yJQfR3w2qzL1w5A2xGqpqOHL9vwzbSqKkpCRXmhCnYfUQzlN5vS7yovHC9r0toFNT6e3skLH2jn3YLai1OUX2DzaSXSa3R6HbUVaytErzVU6fVU+0OWeUU0pKdNypVit+aOZlOhbbDyk0FmkwR8qbqi3GwSXDObGbcZ1R9LP+qrN9TSBodAZa594uzY9K2p36BayE8tCu1piUf0LHTXfuuyjCbBbnC99OUkKPBLy/LMLqXVVnI45q8MQKPeRuqE6o/ikpzakjTaSq65zWAy2bY2zmYXqVRpc+/lxy7xRtRjIYW56erT+4s9gizxIII18OxuXu8RDi7elrjLZqHHn9x8BMGdxPm/W+IudoOT96iwTTeJZfwhSz6E2LqbTWAbfu5DmlvMeSBr3l7QqrMUWQqLvszQLsLGO4CT+6AA0ZSc+wX+Qdy24TbIgjTAOxUPrslvJSts3KRCW/o8kKEsqZDnlbXtIWkeQslFjDpomDebZDmaU7sKtFqGS4AjV4h33zeVSl1+qozLqXptjLO9q+WewzfRkO8XZtxX3fi1rKRQI3YQSV1EPCGHycLjXRmDvqpSqS3PVyqKlHYu3JBIGws04Wuj4d/yLc7TpN5WZv2uLnyqhm3hClgCCVdbSe3DCv8MaNeqyio1aj009J2aCLyaCfzbiBok59XEut6112qqVOU6jdpgnS/5wlbxBUy4eQS3spHVQOfuEhoJpBs97CEKsYcoxB6iEHuIQuwhCrHn/wEAAP//EICdDQAAAAZJREFUAwA7EdnhC1txMQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0zkYsOYYAOO",
        "outputId": "dc0d2152-7fc2-4ddb-cc30-7e17eac7a267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'analyze_query': {'query': {'query': 'Task Decomposition', 'section': 'beginning'}}}\n",
            "\n",
            "----------------\n",
            "\n",
            "{'retrieve': {'context': [Document(id='abf82a11-2b8e-491b-bf93-951faae39a56', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'beginning'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'), Document(id='0d610362-d0e0-491c-93fe-9814af990f7f', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'beginning'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(id='20d73e22-03b8-41a5-bde6-6b7cf880202f', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'beginning'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(id='07ffd909-2fe5-403d-a838-59c5e5a53c33', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'beginning'}, page_content='Self-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)')]}}\n",
            "\n",
            "----------------\n",
            "\n",
            "{'generate': {'answer': 'The beginning of the post introduces task decomposition as a way to enhance model performance on complex tasks. It mentions that Chain of Thought (CoT) prompting is a standard technique where the model is instructed to \"think step by step\" to break down hard tasks into smaller steps. This transforms big tasks into manageable ones, offering insight into the model\\'s thought process.'}}\n",
            "\n",
            "----------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for step in graph.stream(\n",
        "    {\"question\": \"What does the begining of the post say about Task Decomposition?\"},\n",
        "    stream_mode=\"updates\",\n",
        "):\n",
        "    print(f\"{step}\\n\\n----------------\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GK5Vg8BOZGlh",
        "outputId": "5f970afc-c274-474f-99fa-8c1e2e064075"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'analyze_query': {'query': {'query': 'Task Decomposition', 'section': 'end'}}}\n",
            "\n",
            "----------------\n",
            "\n",
            "{'retrieve': {'context': [Document(id='b615a8d2-edc1-4811-8742-9b821aeb23c9', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'end'}, page_content='Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",'), Document(id='3b756659-877c-416e-87d9-f27ddb53462b', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'end'}, page_content='\"content\": \"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully'), Document(id='07feef0d-48dd-4f65-b3c9-c228898ef0a6', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'end'}, page_content='},\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.'), Document(id='a8bcb286-cba7-4f83-9c67-19076bd5bec2', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'end'}, page_content='\"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease')]}}\n",
            "\n",
            "----------------\n",
            "\n",
            "{'generate': {'answer': \"I'm sorry, but this document does not contain information about what the end of the post says about Task Decomposition.\"}}\n",
            "\n",
            "----------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for step in graph.stream(\n",
        "    {\"question\": \"What does the end of the post say about Task Decomposition?\"},\n",
        "    stream_mode=\"updates\",\n",
        "):\n",
        "    print(f\"{step}\\n\\n----------------\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OFrMPzKZJkr",
        "outputId": "4af39c9f-3080-4633-d1ab-2de0a94ce3cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'analyze_query': {'query': {'query': 'Task Decomposition', 'section': 'middle'}}}\n",
            "\n",
            "----------------\n",
            "\n",
            "{'retrieve': {'context': [Document(id='fd928a86-3071-4949-a6aa-8692d29180b3', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'middle'}, page_content=\"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\"), Document(id='ef2f6c3b-5a02-4079-857d-f4d47d11a416', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'middle'}, page_content='(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.'), Document(id='189e01fe-0de6-4142-ac24-4cece575f85e', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'middle'}, page_content='Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\n\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'), Document(id='1cbbfdde-7790-4798-833d-2071b419eba8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'middle'}, page_content='(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:')]}}\n",
            "\n",
            "----------------\n",
            "\n",
            "{'generate': {'answer': 'The middle of the post describes task decomposition as the first stage of the HuggingGPT system. In this stage, the LLM parses user requests into multiple tasks, assigning each task a type, ID, dependencies, and arguments. Few-shot examples are used to guide the LLM in this task parsing and planning process.'}}\n",
            "\n",
            "----------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for step in graph.stream(\n",
        "    {\"question\": \"What does the middle of the post say about Task Decomposition?\"},\n",
        "    stream_mode=\"updates\",\n",
        "):\n",
        "    print(f\"{step}\\n\\n----------------\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzGbVylXZOF0",
        "outputId": "e111036c-b934-4fd9-802c-624dc321725a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'analyze_query': {'query': {'query': 'Task Decomposition', 'section': 'beginning'}}}\n",
            "\n",
            "----------------\n",
            "\n",
            "{'retrieve': {'context': [Document(id='abf82a11-2b8e-491b-bf93-951faae39a56', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'beginning'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'), Document(id='0d610362-d0e0-491c-93fe-9814af990f7f', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'beginning'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(id='20d73e22-03b8-41a5-bde6-6b7cf880202f', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'beginning'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(id='07ffd909-2fe5-403d-a838-59c5e5a53c33', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'beginning'}, page_content='Self-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)')]}}\n",
            "\n",
            "----------------\n",
            "\n",
            "{'generate': {'answer': 'The post describes task decomposition as breaking down large tasks into smaller, manageable steps to handle complex tasks efficiently. It mentions Chain of Thought (CoT) and Tree of Thoughts as techniques to decompose tasks. Task decomposition can be done by LLMs with prompting, task-specific instructions, or human inputs.'}}\n",
            "\n",
            "----------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for step in graph.stream(\n",
        "    {\"question\": \"What does this post says about Task Decomposition?\"},\n",
        "    stream_mode=\"updates\",\n",
        "):\n",
        "    print(f\"{step}\\n\\n----------------\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQsqr5h-Krjy"
      },
      "source": [
        "# AGENTIC RAG\n",
        "In this tutorial we will build a retrieval agent. Retrieval agents are useful when you want an LLM to make a decision about whether to retrieve context from a vectorstore or respond to the user directly.\n",
        "\n",
        "By the end of the tutorial we will have done the following:\n",
        "\n",
        "Fetch and preprocess documents that will be used for retrieval.\n",
        "Index those documents for semantic search and create a retriever tool for the agent.\n",
        "Build an agentic RAG system that can decide when to use the retriever tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-OnG1CQuZT1B"
      },
      "outputs": [],
      "source": [
        "! pip install -U --quiet langgraph \"langchain[openai]\" langchain-community langchain-text-splitters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1HvCNjlfK91Y"
      },
      "outputs": [],
      "source": [
        "# import getpass\n",
        "# import os\n",
        "\n",
        "\n",
        "# def _set_env(key: str):\n",
        "#     if key not in os.environ:\n",
        "#         os.environ[key] = getpass.getpass(f\"{key}:\")\n",
        "\n",
        "\n",
        "# _set_env(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyv2MBTiMXYv",
        "outputId": "88606931-ce86-4bf4-d9bd-357f508545af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "urls = [\n",
        "    \"https://lilianweng.github.io/posts/2024-11-28-reward-hacking/\",\n",
        "    \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\",\n",
        "    \"https://lilianweng.github.io/posts/2024-04-12-diffusion-video/\",\n",
        "]\n",
        "\n",
        "docs = [WebBaseLoader(url).load() for url in urls]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qhwsLUoOMcUj"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=100, chunk_overlap=50\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(docs_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cj1glDyWMgAf"
      },
      "outputs": [],
      "source": [
        "# from langchain_core.vectorstores import InMemoryVectorStore\n",
        "# from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# vectorstore = InMemoryVectorStore.from_documents(\n",
        "#     documents=doc_splits, embedding=OpenAIEmbeddings()\n",
        "# )\n",
        "# retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZkL0BJR3MmgZ"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
        "\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vyv0jAaeNKNY"
      },
      "outputs": [],
      "source": [
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "vectorstore = InMemoryVectorStore.from_documents(\n",
        "    documents=doc_splits, embedding=embeddings\n",
        ")\n",
        "retriever = vectorstore.as_retriever()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn6dPVCFN1T1"
      },
      "source": [
        "Create a retriever tool using LangChain's prebuilt create_retriever_tool:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2tNYNq-SNyeW"
      },
      "outputs": [],
      "source": [
        "from langchain.tools.retriever import create_retriever_tool\n",
        "\n",
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    \"retrieve_blog_posts\",\n",
        "    \"Search and return information about Lilian Weng blog posts.\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "ChZ1CfvzN95n",
        "outputId": "547f0bae-120d-42c2-ce05-4c13e1efaa6a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'(Note: Some work defines reward tampering as a distinct category of misalignment behavior from reward hacking. But I consider reward hacking as a broader concept here.)\\nAt a high level, reward hacking can be categorized into two types: environment or goal misspecification, and reward tampering.\\n\\nReward hacking examples in LLM tasks#\\n\\nA language model for generating summarization is able to explore flaws in the ROUGE metric such that it obtains high score but the generated summaries are barely readable. (Link)\\nA coding model learns to change unit test in order to pass coding questions. (Link)\\nA coding model may learn to directly modify the code used for calculating the reward. (Link)\\n\\nReward hacking examples in real life#\\n\\nAmodei et al. (2016) summarized that reward hacking, mainly in RL setting, may occur due to:\\n\\nReward hacking occurs when a reinforcement learning (RL) agent exploits flaws or ambiguities in the reward function to achieve high rewards, without genuinely learning or completing the intended task. Reward hacking exists because RL environments are often imperfect, and it is fundamentally challenging to accurately specify a reward function.'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever_tool.invoke({\"query\": \"types of reward hacking\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB61vslzOGMG"
      },
      "source": [
        "Now we will start building components (nodes and edges) for our agentic RAG graph. Note that the components will operate on the MessagesState — graph state that contains a messages key with a list of chat messages.\n",
        "\n",
        "1. Build a generate_query_or_respond node. It will call an LLM to generate a response based on the current graph state (list of messages). Given the input messages, it will decide to retrieve using the retriever tool, or respond directly to the user. Note that we're giving the chat model access to the retriever_tool we created earlier via .bind_tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DE6aNjJpOHa_"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import MessagesState\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "response_model = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\",temperature=0)\n",
        "\n",
        "\n",
        "def generate_query_or_respond(state: MessagesState):\n",
        "    \"\"\"Call the model to generate a response based on the current state. Given\n",
        "    the question, it will decide to retrieve using the retriever tool, or simply respond to the user.\n",
        "    \"\"\"\n",
        "    response = (\n",
        "        response_model\n",
        "        .bind_tools([retriever_tool]).invoke(state[\"messages\"])\n",
        "    )\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv92y71bP50k"
      },
      "source": [
        "in case of generic query it wont go to retrieve node at all, where as queries that requires semantic retrieval agent will call retrieval node and then generate node\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNE80QzwPn5X",
        "outputId": "00072e1b-e7f9-4d04-c2a4-f9ccbbe8bfaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello! How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "input = {\"messages\": [{\"role\": \"user\", \"content\": \"hello!\"}]}\n",
        "generate_query_or_respond(input)[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ3twNdfP0WU",
        "outputId": "c26c0c79-c4b1-4c11-c7f4-3fd04b28ffef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve_blog_posts (e71aa5c8-adac-4e93-9481-97ece1d95d93)\n",
            " Call ID: e71aa5c8-adac-4e93-9481-97ece1d95d93\n",
            "  Args:\n",
            "    query: types of reward hacking\n"
          ]
        }
      ],
      "source": [
        "input = {\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What does Lilian Weng say about types of reward hacking?\",\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "generate_query_or_respond(input)[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzSM5MnbQW-2"
      },
      "source": [
        "1. Add a conditional edge — grade_documents — to determine whether the retrieved documents are relevant to the question. We will use a model with a structured output schema GradeDocuments for document grading. The grade_documents function will return the name of the node to go to based on the grading decision (generate_answer or rewrite_question):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DTXEwpyJP-SG"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "\n",
        "GRADE_PROMPT = (\n",
        "    \"You are a grader assessing relevance of a retrieved document to a user question. \\n \"\n",
        "    \"Here is the retrieved document: \\n\\n {context} \\n\\n\"\n",
        "    \"Here is the user question: {question} \\n\"\n",
        "    \"If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\"\n",
        "    \"Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\n",
        ")\n",
        "\n",
        "\n",
        "class GradeDocuments(BaseModel):\n",
        "    \"\"\"Grade documents using a binary score for relevance check.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Relevance score: 'yes' if relevant, or 'no' if not relevant\"\n",
        "    )\n",
        "\n",
        "\n",
        "grader_model = init_chat_model(\"gemini-2.0-flash\",model_provider=\"google_genai\",temperature=0)\n",
        "\n",
        "\n",
        "def grade_documents(\n",
        "    state: MessagesState,\n",
        ") -> Literal[\"generate_answer\", \"rewrite_question\"]:\n",
        "    \"\"\"Determine whether the retrieved documents are relevant to the question.\"\"\"\n",
        "    question = state[\"messages\"][0].content\n",
        "    context = state[\"messages\"][-1].content\n",
        "\n",
        "    prompt = GRADE_PROMPT.format(question=question, context=context)\n",
        "    response = (\n",
        "        grader_model\n",
        "        .with_structured_output(GradeDocuments).invoke(\n",
        "            [{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "    )\n",
        "    score = response.binary_score\n",
        "\n",
        "    if score == \"yes\":\n",
        "        return \"generate_answer\"\n",
        "    else:\n",
        "        return \"rewrite_question\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHjbUAqDRCaw"
      },
      "source": [
        "Rewrite question¶\n",
        "1. Build the rewrite_question node. The retriever tool can return potentially irrelevant documents, which indicates a need to improve the original user question. To do so, we will call the rewrite_question node:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "srqkNBxSQ0_-"
      },
      "outputs": [],
      "source": [
        "REWRITE_PROMPT = (\n",
        "    \"Look at the input and try to reason about the underlying semantic intent / meaning.\\n\"\n",
        "    \"Here is the initial question:\"\n",
        "    \"\\n ------- \\n\"\n",
        "    \"{question}\"\n",
        "    \"\\n ------- \\n\"\n",
        "    \"Formulate an improved question:\"\n",
        ")\n",
        "\n",
        "\n",
        "def rewrite_question(state: MessagesState):\n",
        "    \"\"\"Rewrite the original user question.\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    question = messages[0].content\n",
        "    prompt = REWRITE_PROMPT.format(question=question)\n",
        "    response = response_model.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
        "    return {\"messages\": [{\"role\": \"user\", \"content\": response.content}]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UwwPmHQyRN98"
      },
      "outputs": [],
      "source": [
        "GENERATE_PROMPT = (\n",
        "    \"You are an assistant for question-answering tasks. \"\n",
        "    \"Use the following pieces of retrieved context to answer the question. \"\n",
        "    \"If you don't know the answer, just say that you don't know. \"\n",
        "    \"Use three sentences maximum and keep the answer concise.\\n\"\n",
        "    \"Question: {question} \\n\"\n",
        "    \"Context: {context}\"\n",
        ")\n",
        "\n",
        "\n",
        "def generate_answer(state: MessagesState):\n",
        "    \"\"\"Generate an answer.\"\"\"\n",
        "    question = state[\"messages\"][0].content\n",
        "    context = state[\"messages\"][-1].content\n",
        "    prompt = GENERATE_PROMPT.format(question=question, context=context)\n",
        "    response = response_model.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zWyb7VHYRPF6"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.prebuilt import tools_condition\n",
        "\n",
        "workflow = StateGraph(MessagesState)\n",
        "\n",
        "# Define the nodes we will cycle between\n",
        "workflow.add_node(generate_query_or_respond)\n",
        "workflow.add_node(\"retrieve\", ToolNode([retriever_tool]))\n",
        "workflow.add_node(rewrite_question)\n",
        "workflow.add_node(generate_answer)\n",
        "\n",
        "workflow.add_edge(START, \"generate_query_or_respond\")\n",
        "\n",
        "# Decide whether to retrieve\n",
        "workflow.add_conditional_edges(\n",
        "    \"generate_query_or_respond\",\n",
        "    # Assess LLM decision (call `retriever_tool` tool or respond to the user)\n",
        "    tools_condition,\n",
        "    {\n",
        "        # Translate the condition outputs to nodes in our graph\n",
        "        \"tools\": \"retrieve\",\n",
        "        END: END,\n",
        "    },\n",
        ")\n",
        "\n",
        "# Edges taken after the `action` node is called.\n",
        "workflow.add_conditional_edges(\n",
        "    \"retrieve\",\n",
        "    # Assess agent decision\n",
        "    grade_documents,\n",
        ")\n",
        "workflow.add_edge(\"generate_answer\", END)\n",
        "workflow.add_edge(\"rewrite_question\", \"generate_query_or_respond\")\n",
        "\n",
        "# Compile\n",
        "graph = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "G8IpsaMaSHjv",
        "outputId": "08a35ed3-45f0-4810-d6d4-10f7e2efa853"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs7YxzNXSKZI",
        "outputId": "84bbf643-1247-4ff2-a618-71b51ab2f73a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Update from node generate_query_or_respond\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve_blog_posts (00ce3423-049c-4e14-b2f7-fa0b466d2a40)\n",
            " Call ID: 00ce3423-049c-4e14-b2f7-fa0b466d2a40\n",
            "  Args:\n",
            "    query: types of reward hacking\n",
            "\n",
            "\n",
            "\n",
            "Update from node retrieve\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve_blog_posts\n",
            "\n",
            "(Note: Some work defines reward tampering as a distinct category of misalignment behavior from reward hacking. But I consider reward hacking as a broader concept here.)\n",
            "At a high level, reward hacking can be categorized into two types: environment or goal misspecification, and reward tampering.\n",
            "\n",
            "Reward hacking examples in LLM tasks#\n",
            "\n",
            "A language model for generating summarization is able to explore flaws in the ROUGE metric such that it obtains high score but the generated summaries are barely readable. (Link)\n",
            "A coding model learns to change unit test in order to pass coding questions. (Link)\n",
            "A coding model may learn to directly modify the code used for calculating the reward. (Link)\n",
            "\n",
            "Reward hacking examples in real life#\n",
            "\n",
            "Amodei et al. (2016) summarized that reward hacking, mainly in RL setting, may occur due to:\n",
            "\n",
            "Reward hacking occurs when a reinforcement learning (RL) agent exploits flaws or ambiguities in the reward function to achieve high rewards, without genuinely learning or completing the intended task. Reward hacking exists because RL environments are often imperfect, and it is fundamentally challenging to accurately specify a reward function.\n",
            "\n",
            "\n",
            "\n",
            "Update from node generate_answer\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Lilian Weng categorizes reward hacking into two types: environment or goal misspecification and reward tampering. Reward hacking occurs when an RL agent exploits flaws or ambiguities in the reward function to achieve high rewards without completing the intended task. This is because RL environments are often imperfect, and it is challenging to accurately specify a reward function.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for chunk in graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"What does Lilian Weng say about types of reward hacking?\",\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "):\n",
        "    for node, update in chunk.items():\n",
        "        print(\"Update from node\", node)\n",
        "        update[\"messages\"][-1].pretty_print()\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytF-ANRySXAC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
